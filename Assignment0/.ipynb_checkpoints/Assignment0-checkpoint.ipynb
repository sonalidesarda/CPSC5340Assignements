{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Assignment 0 -- TCSS 5340\n",
    "\n",
    "In this assignment you are going to read in some text files containing movie reviews and index them so you can perform boolean AND/OR queries.\n",
    "\n",
    "The directory **data** has one file per review.   The name of the file will act as the document ID, so for example the file **data/Dog4.txt** will have the Document ID **Dog4**.  The file contains the review text.\n",
    "\n",
    "The query operators will be \n",
    "* **query(term)** -- Term is a string, return a set of the IDs of all documents that contain it\n",
    "* **andQuery(arg1, arg2)** -- The arguments are either strings or sets of document IDs.  Return a set of the IDs of the documents at the *intersection* of the two arguments\n",
    "* **orQuery(arg1, arg2)** -- The arguments are either strings or sets of document IDs.  Return a set of the IDs of the documents at the *union* of the two arguments\n",
    "\n",
    "The more complicated definition of **andQuery** and **orQuery** is because we want to nest them.  For example, these both need to work.\n",
    "<pre>\n",
    "orQuery('hello', 'world')\n",
    "orQuery('hello', orQuery('world', 'earth'))\n",
    "</pre>\n",
    "\n",
    "Three more examples (output below):\n",
    "<pre>\n",
    "query('movie')\n",
    "andQuery('yellow', 'lab')\n",
    "andQuery(andQuery('salome', orQuery('good', 'excellent')), 'opera')\n",
    "</pre>\n",
    "\n",
    "We will implement the solution in two phases:\n",
    "* The indexing phase;  process the documents in the directory and build the inverted index\n",
    "* The query phase;  given an inverted index, compute the document IDs that satisfy a query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phase 1:  Indexing Phase\n",
    "\n",
    "Result of the indexing phase will be a function \n",
    "<pre>\n",
    "indexDocuments(directory) -> invertedIndex\n",
    "</pre>\n",
    "where the inverted index is a dictionary that maps a term to all the document IDs containing that term\n",
    "\n",
    "Build the indexDocuments function in a series of steps as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#  Iterate over all the files in the data directory.  For each:\n",
    "#    -- extract its file basename as the docID\n",
    "#    -- read the file as a single string\n",
    "\n",
    "#  Function getIDsAndReviews(directoryName)\n",
    "#    Input -- the name of the directory holding the documents\n",
    "#    Output -- a dictionary whose keys are document IDs and the value for the key is the full unprocessed review text\n",
    "\n",
    "# Helper function takes a file name as input and extracts the file basename (document ID)\n",
    "def getDocID(filename):\n",
    "    return os.path.splitext(os.path.basename(filename))[0]\n",
    "\n",
    "#  Return a dictionary of {docID: review_text} pairs, one for each file in the data directory\n",
    "#  Iterate over all files in the directory\n",
    "#    For each filename, extract the docID and read file contents.  Put that pair into a dictionary\n",
    "def getIDsAndReviews(dataDir):\n",
    "    ## YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some heavily edited output.  Notice that the reviews are pretty messy, they have newlines, HTML tags, mixed capitalization, etc.\n",
    "\n",
    "<pre>\n",
    "idsAndReviews = getIDsAndReviews()\n",
    "print(len(idsAndReviews))\n",
    "print(idsAndReviews)\n",
    "\n",
    "13\n",
    "{'Dog1': 'You don't have to own a Yellow Lab to absolutley love this movie, \\n but ...',  \n",
    " 'Dog2': '... mesmerized by this movie. &lt;em&gt;The adventures of a lost boy and dog&lt;/em&gt;....',\n",
    "   ...\n",
    " 'DooWop1':  'Excellent, excellent performers.  Excellent video and audio quality....', \n",
    " 'Salome5':  'I saw this production on TV many years ago and thought then that it was really ...'\n",
    "}\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next tokenize the review document -- split the review into words and clearn each word by removing non-letters\n",
    "#  and converting all letters to lower case, then remove empty strings\n",
    "\n",
    "import re\n",
    "def tokenizeWord(word):\n",
    "    regex = re.compile('[^a-zA-Z]')\n",
    "    return regex.sub('', word).lower()\n",
    "\n",
    "#   Tokenize a single review (string)\n",
    "#  Input -- a review (string)\n",
    "#  Output -- the cleaned review -- a list of words (strings), each word is cleaned\n",
    "def tokenizeDocument(document):\n",
    "    ## YOUR CODE HERE\n",
    "\n",
    "# Input -- a dictionary as produced by getIDsAndDocuments\n",
    "# Output -- a dictionary with the same keys, but each value is the cleaned review (a list of strings)\n",
    "def tokenizeDocuments(idToDocuments):\n",
    "    ## YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that all special characters have been removed, the words are all letters, and all in lower case.\n",
    "Removing all special characters might be too extreme in a real system, for example our code will convert *don't* to *dont* *well-made* to *wellmade* which changes the meaning of the word.  But that's what most systems do and they seem to \n",
    "work OK!\n",
    "\n",
    "<pre>\n",
    "{'Dog1': ['you', 'do', 'have', 'to', 'own', 'a', 'yellow', 'lab', ...],\n",
    " 'DooWop1': ['excellent', 'excellent', 'performers', 'excellent', ...],\n",
    " 'Joe1': ['im', 'not', 'a', 'tim', 'allen', 'fan', 'i', 'had', 'only', 'watched', ...],\n",
    "  ... \n",
    " 'Salome5': ['i', 'saw', 'this', 'production', 'on', 'tv', 'many', 'years', 'ago',...]}\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next invert the index.  We want to invert a dictionary of the form  docID -> terms to a dictionary\n",
    "#  of the form term -> docIDs\n",
    "\n",
    "#  Input is a dictionary docID -> termList as produced by tokenizeDocuments\n",
    "#  Output is a list of dictionaries, one per review, each of the form   term -> {docID}\n",
    "#    Notice that for the dictionary value, like {docID}, the curly brackets means that this is a set, not a list.  \n",
    "\n",
    "def buildTermToDocDictionaries(docsToTerms):\n",
    "    ## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a list of 13 dictionaries.  Each dictionary has keys which are terms, and a value which is a set containing exactly one document ID\n",
    "\n",
    "<pre>\n",
    "[{'you': {'Dog1'},\n",
    "  'do': {'Dog1'},\n",
    "  'have': {'Dog1'},\n",
    "  ...\n",
    "  }, \n",
    " {'as': {'Dog2'},\n",
    "  'owners': {'Dog2'},\n",
    "\n",
    "  'wildlife': {'Dog4'},\n",
    "  'wolves': {'Dog4'},\n",
    "  'wild': {'Dog4'},\n",
    "  'cats': {'Dog4'},\n",
    "  ...\n",
    "  },\n",
    "  ...\n",
    " {'excellent': {'DooWop1'},\n",
    "  'performers': {'DooWop1'},\n",
    "  ...\n",
    "  },\n",
    "  ...\n",
    "  ]\n",
    " </pre>\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dictionaries to produce the inverted index --\n",
    "#   for example we want term: {docID1, docID2, ....}\n",
    "\n",
    "# Input:  a list of dictionaries of the form term -> {docID} as produced by buildTermToDocDictionaries\n",
    "# Output: a dictionary of the form term -> {docID1, docID2, ...} which are \n",
    "def mergeIndexes(indexes):\n",
    "    ## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is edited output, so yours won't be in this order, though the values should be the same.  This is the inverted index we will query against.\n",
    "\n",
    "<pre>\n",
    "{ 'comforts': {'Dog4'}, \n",
    "  'about': {'Salome1'}, ...\n",
    "  'first': {'DooWop2', 'Joe2', 'Salome2'}, \n",
    "  'with': {'DooWop2', 'Dog4', 'Joe1', 'Salome5', 'Salome2', 'Dog3', 'Salome1', 'Joe2', 'Salome4', 'Salome3'}, \n",
    "  'thought': {'DooWop2', 'Salome5'}, \n",
    "  'buy': {'DooWop1', 'Dog2', 'Salome1'}, \n",
    "  'while': {'DooWop2', 'Dog4', 'Dog1', 'Salome1', 'Salome4'}, \n",
    "  ...\n",
    "}\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  As a final step, bundle all these functions into a single index-generation function\n",
    "def indexReviews(dataDir):\n",
    "    ## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phase 2: Query Phase\n",
    "\n",
    "Now it's easy to do queries on the index\n",
    "\n",
    "* for a simple query (single term) just look up the term in the index and retrieve its doc IDs\n",
    "* for an AND query, take the intersection of the doc IDs\n",
    "* for an OR query, take the union of the doc IDs\n",
    "\n",
    "The complication is that in order to do nesting, *and_query* and *or_query* need to accept either a term (string) or a set of docIDs as input.    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  We are going to implement our query processor as a Python class so we can \n",
    "##  hold the inverted index as an instance variable, and not have to regenerate it \n",
    "##  for every query\n",
    "\n",
    "class QueryProcessor:\n",
    "    def __init__(self, dataDir):\n",
    "        ## YOUR CODE HERE\n",
    "    def query(self, term):\n",
    "        ## YOUR CODE HERE\n",
    "    def andQuery(self, term1, term2):\n",
    "        ## YOUR CODE HERE\n",
    "    def orQuery(self, term1, term2):\n",
    "        ## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dog4', 'Dog2', 'Joe2', 'Joe1', 'Dog1', 'Dog3'}\n",
      "{'Dog2', 'Dog1'}\n",
      "{'Salome5'}\n",
      "{'Dog4', 'DooWop2', 'Joe2', 'Joe1', 'Salome5', 'DooWop1'}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "qp = QueryProcessor(\"data\")\n",
    "\n",
    "#  Query on a single term gives back a set of document IDs\n",
    "print(qp.query('movie'))\n",
    "\n",
    "#  And query\n",
    "print(qp.andQuery('yellow', 'lab'))\n",
    "\n",
    "# Nested query\n",
    "print(qp.andQuery(qp.andQuery('salome', qp.orQuery('good', 'excellent')), 'opera'))\n",
    "\n",
    "# Four-way OR is awkward!\n",
    "print(qp.orQuery(qp.orQuery('good', 'excellent'), qp.orQuery('liked', 'loved')))\n",
    "\n",
    "\n",
    "{'Dog4', 'Dog3', 'Dog2', 'Dog1', 'Joe1', 'Joe2'}\n",
    "{'Dog1', 'Dog2'}\n",
    "{'Salome5'}\n",
    "{'DooWop2', 'Dog4', 'Joe1', 'Joe2', 'Salome5', 'DooWop1'}\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------\n",
    "\n",
    "How to hand in:\n",
    "\n",
    "Prior to handing in this notebook,\n",
    "* Delete the first cell, the one with the instructions\n",
    "* Delete all cells with sample output\n",
    "* Delete all cells with your testing code\n",
    "* Delete any comments you added that are not documentation\n",
    "* Be sure that your code does not generate any output through print statements\n",
    "* Your notebook should just have the function definitions that implement the indexing phase and the query processor\n",
    "* Put a cell at the top identifying you, and include the course number and that this is Assignment 0\n",
    "* Delete this cell too!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
