{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification Using Spacy and Scikit-Learn\n",
    "\n",
    "In this exercise you will use Spacy to do the document preprocessing, then use Scikit-Learn Naive Bayes Classifier to categorize news stories as to their topic.\n",
    "\n",
    "The main exploration will be to use features of the Spacy text analysis pipeline to provide good term features that will be used in the document classifier.\n",
    "\n",
    "The directory *documents* contains BBC news articles that are about one of these topics:  business, entertainment, politics, sport, and tech.  The subfolder under *documents* indicates the true category.  You can assume that every document is \"about\" exactly one category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function from the lab to train a classifier and print the cross-validation accuracy score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def eval_classifier(clf, X, y):\n",
    "    def cross_validate(clf, x, y):\n",
    "        return cross_val_score(clf, x, y, cv=10).mean()\n",
    "    clf.fit(X,y)\n",
    "    print(f\"Results for {clf}\")\n",
    "    print(f\"Cross validation mean accuracy: {cross_validate(clf, X, y)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to help in loading the training set\n",
    "#\n",
    "# Argument is a directory with one subdirectory per topic, and the subdirectory name is \n",
    "# the topic name.  Each subdirectory contains text files, which are articles that are \"about\" that topic.\n",
    "# \n",
    "# Return value from this function is a list of the form [(document_text, topic), ... ]   where document_text is a string\n",
    "# containing the full document content, and topic is the topic label (a string)\n",
    "\n",
    "import os\n",
    "\n",
    "def load_docs(dir=\"documents\"):\n",
    "    docs = []\n",
    "    for root, dirs, _ in os.walk(dir):\n",
    "        for dir in dirs:\n",
    "            for r2, d2, f2 in os.walk(os.path.join(os.path.join(root, dir))):\n",
    "                for f in f2:\n",
    "                    docs.append((open(os.path.join(root, dir, f)).read(), dir))\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Inputs are (1) the root location of the training set, and \n",
    "#            (2) a tokenizer function that takes a document string, and returns a list \n",
    "#                of term strings.  \n",
    "# Return value from this function is [(term_string, label), ...]\n",
    "\n",
    "def tokenize_docs(docs, tokenizer):\n",
    "    return [(tokenizer(t[0]), t[1]) for t in docs]\n",
    "\n",
    "###################\n",
    "#  Just chains together load_docs and tokenize_docs\n",
    "\n",
    "def load_and_tokenize_docs(dir, tokenizer):\n",
    "    return tokenize_docs(load_docs(dir), tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, this example applies a very simple tokenizer that just splits the input\n",
    "according to the Spacy regexp.  Notice this is not what a good tokenizer should do, \n",
    "since it does not case fold and does not deal with punctuation in any reasonable way.\n",
    "\n",
    "<pre>\n",
    "load_and_tokenize_docs(\"documents\", tokenize_text)\n",
    "\n",
    "[(['Call', 'centre', 'users', \"'\", 'lose', 'patience', \"'\", '\\n\\n', ... ], 'business'), ... ]\n",
    "</pre>\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# If you use Spacy to preprocess the input documents but are using scikit-learn\n",
    "# to do the classification, you need a vectorizer that skips the preprocessing steps.\n",
    "# This function returns a vectorizer with no-ops for tokenizer and preprocessor.  \n",
    "\n",
    "def dummyCountVectorizer():\n",
    "    def dummy(doc):\n",
    "        return doc\n",
    "    return CountVectorizer(tokenizer=dummy, preprocessor=dummy)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First establish a baseline classification accuracy:  don't use Spacy at all -- instead just use the scikit-learn preprocessor and tokenizer, as we did in lab, using a \"real\" Count Vectorizer from scikit-learn, and a Multinomial Naive Bayes classifier.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Loads documents, instantiates a count vectorizer and Multinomial Naive Bayes\n",
    "# classifier, trains the model and calls eval_classifier to get the cross_val accuracy\n",
    "def baseline_accuracy(dir=\"documents\"):\n",
    "  # Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example,\n",
    "\n",
    "<pre>\n",
    "baseline_accuracy()\n",
    "\n",
    "Results for MultinomialNB()\n",
    "Cross validation mean accuracy: 0.89\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next try the simplest possible Spacy tokenizer -- default splitting pattern, then just use the text of each token for te term (that is the tokenizer in the example above).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argument is location of training data.  Use a very simple Spacy tokenizer, and train a MultinomialNB model.\n",
    "# Function calls eval_classifier, which prints the cross-val accuracy\n",
    "\n",
    "def basic_spacy_accuracy(dir=\"documents\"):\n",
    "    # YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example.  This is surprising -- even with a VERY crude tokenizer, accuracy is pretty good, but not as good as the scikit-learn baseline.\n",
    "<pre>\n",
    "basic_spacy_accuracy()\n",
    "\n",
    "Results for MultinomialNB()\n",
    "Cross validation mean accuracy: 0.8699999999999999\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use additional Spacy pipeline features to improve your tokenizer.  For example:  case folding, removing punctuation, lemmatization, stop word removal.   This function will be the same as basic_spacy_accuracy, except using a different tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function is identical to basic_spacy_accuracy, but uses a better tokenizer\n",
    "\n",
    "def better_spacy_accuracy(dir=\"documents\"):\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example.  Some improvement using a better tokenizer!  Also, not surprising this value is the same as the scikit-learn model, as the vectorizers are almost identical.\n",
    "<pre>\n",
    "better_spacy_accuracy()\n",
    "\n",
    "Results for MultinomialNB()\n",
    "Cross validation mean accuracy: 0.8866666666666667\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use the result of the Named Entity Recognition to try to improve the classifier.  \n",
    "\n",
    "An idea to start\n",
    "* If your tokenizer generates a \"constant\" token like TOKEN_MONEY for every piece of the document that was classified as entity type MONEY, that signals that there was a money amount in the text -- which is a good thing to do -- but does not specify the amount of money.  Leaving out the amount of money is probably a good thing to do.  There are several similar entity types, like CARDINAL, PERCENT, QUANTITY, etc.  for which including the entity token but not the actual document text is probably a good idea.\n",
    "* For other entities like ORG or GPE, it's probably useful to insert a \"constant\" token like TOKEN_GPE to signify that there was a location name in the text, but it also might be useful to include the document token(s) as well.\n",
    "\n",
    "But please experiment with various ideas about how to incorporate the NER entities into the document's token stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function is identical to basic_spacy_accuracy and better_spacy_accuracy, but uses a tokenizer that includes \n",
    "# NER entities\n",
    "\n",
    "def ner_spacy_accuracy(dir=\"documents\"):\n",
    "    ## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example.  Tragedy!  For me, NER did not improve things at all!   But I'm sure you will do better!\n",
    "<pre>\n",
    "ner_spacy_accuracy()\n",
    "\n",
    "Results for MultinomialNB()\n",
    "Cross validation mean accuracy: 0.8866666666666667\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
