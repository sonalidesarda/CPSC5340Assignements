{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 3 &ndash; Text Classification\n",
    "\n",
    "This assignment is about text classification.   We are going to predict the category of a product based on information we have about the product from its product record and its reviews.\n",
    "\n",
    "You are given training data in the form of product and review information for 1500 products.  Each is labeled as being in the category *Books* or  *Movies & TV* or *Music*\n",
    "\n",
    "There are two parts to the assignment:  delivering the classifier, and documenting the research that went into choosing the best model.\n",
    "\n",
    "You will be given a \"labeled training set\" which is one products file and one reviews file, same format as last assignment.  \n",
    "In the products file, all products are from one of the three categories above, and in the reviews file, all of the reviews are associated with one of the products in the product file.  You will notice also that all the fields in the products file have been deleted except for the ASIN, the price, and the category.\n",
    "\n",
    "You will build a classifier that will take as input the names of two files containing labeled test data, and will produce classifications for those records. A big part of the assignment is exploring, evaluating, and document choices you make as you build your classifier. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Parts to the Assignment\n",
    "\n",
    "In the first part of the assignment you will put code to train your model and to preprocess test data. After that, you will answer some questions about experiments you conducted and decisions you made in building your \"best\" model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Model and its Evaluation\n",
    "\n",
    "(Just so you don't get confused, although these function definitions appear before the analysis, this model represents your best model which you developed as part of the analysis that you will provide below.)\n",
    "\n",
    "You will write two functions that will allow evaluation of your model, *build_model* and *prepare_data*.\n",
    "\n",
    "The first reads training data, prepares the data (extracts fields from the files, builds the response variable, vectorizes the X, and possibly reduces the feature set), then trains the model on that data (using the fit method).  The model returned should be ready to make predictions -- i.e. you have already fitted the model.\n",
    "\n",
    "The second just does the preprocessing steps, producing an X matrix.  We didn't see this separation between preparing the data and fitting the model in class, but it is necessary in practice.  Typically you would build and optimize a model, then ship it into production.  In production the model would take new input data and call the model to get its prediction.  But in order to call the production model, the data must be preprocessed in the same way data was preprocessed during training.  That's what the *prepare_data* method does.    \n",
    "\n",
    "Hint:  in training the model you will have built a vectorizer, and you need to use that same vectorizer in preparing the data.  It is OK to use a global variable to store that vectorizer that will be set by *build_model* and then read by *prepare_data*.\n",
    "\n",
    "One last requirement.  You will need to do a numeric recoding of the *y* variable, i.e. the product category.  So I can test your model, you must code your response variable as follows\n",
    "\n",
    "* Books category is coded as **0**\n",
    "* Movies & TV category is coded as **1**\n",
    "* Music category is coded as **2**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate your model, I will first call your *build_model* function to train it.  I will use the same files provided for you in the repository.   After training the model, I will call prepare_data using a different set of test data, then evaluate the model by calling its predict method on the X matrix returned by prepare_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a model -- an object that at least implements a predict method.\n",
    "# The two parameters are names of files containing labeled training data\n",
    "# The model returned should already be trained on (fitted to) the data in those two files\n",
    "\n",
    "def build_model(product_file_name=\"products.txt\", review_file_name=\"reviews.txt\"):\n",
    "    # Your code here\n",
    "    return aModel\n",
    "\n",
    "# Returns an X matrix which is prepared using the same preprocessing\n",
    "# steps used to build and train the model returned by build_model above.\n",
    "# Notice that although the product category might be in the product file, you cannot use it in\n",
    "# this function.  In fact the only reason the product file is relevant at all is that you might\n",
    "# have used the product *price* attribute in training your model, and if so you will have to read it\n",
    "# from the product file.  \n",
    "\n",
    "def prepare_data(product_file_name, review_file_name):\n",
    "    # Your code here\n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------\n",
    "### Documenting your Decisions\n",
    "\n",
    "From this point down there should be no code cells.  Your analysis should have supporting data (tables, graphics), but please render it in markdown, otherwise it will go away when I test your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation and Analysis\n",
    "\n",
    "In answering these questions, please be sure to show your work, for example output of commands you used to gather data supporting your decisions.   For each of the cells below containing a question, please leave the question header and text in the notbook you subnmit.  Put your answer in markdown in the same cell, and add additional markdown cells below the question/answer cell for supporting data (output, tables, graphics).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "#### Model Quality\n",
    "\n",
    "What do you expect the accuracy of your model to be on a new set of product records it has not seen before?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------\n",
    "#### Input Fields\n",
    "\n",
    "What input fields from the product and review records did you include in training your model (prior to any feature selection)?  How did you decide which fields to use and which to omit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------\n",
    "#### Preprocessing\n",
    "\n",
    "What preprocessing steps did you use?  At minimum you must evaluate stemming, tokenizing, stop word removal.  How did you decide which steps improved the model and which did not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Your answer here.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------\n",
    "#### Vectorization\n",
    "\n",
    "What technique did you use to turn the input features into a feature vector?  How did you make that choice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Your answer here.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------\n",
    "####  Feature Selection\n",
    "\n",
    "It is important to examine and understand the model features both to convince that the important features are plausible, and to consider removing the unimportant features.  What features did you use in the model, and how did you make that choice?  List some of the most important features.  Are you convinced that they are are accurate exemplars of the class, or might they be artifacts of the training set?  List some of the least important features -- do they suggest ways to cut down the model size without significantly affecting accuracy?  \n",
    "\n",
    "In class we looked at three ways of estimating the impact of a term on a model\n",
    "\n",
    "* Frequency-based selection\n",
    "* Mutual information\n",
    "* Feature log probabilities, i.e. $P(f_i | C)$\n",
    "\n",
    "How different are the three measures, i.e. do they all tend to rank the same variables as significant and insignificant?  Which did you use in your model, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Your answer here.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------\n",
    "#### Algorithm\n",
    "\n",
    "Which classification algorithm did you use;  what alternatives did you explore and how did you make the choice?  What hyperparameter optimization did you perform?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Your answer here.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------\n",
    "#### Understanding Misclassifications\n",
    "\n",
    "Even though misclassifications are inevitable, it is important to understand *why* your algorithm makes errors, and whether it is making \"understandable\" errors.   Choose several examples of misclassification and informally explain why you believe the classifier made the wrong choice.  Is/was there anything you might be able to do in terms of feature engineering to fix some misclassifications?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Your answer here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
