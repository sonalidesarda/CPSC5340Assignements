{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has some documentation, and also specifics about what to keep in this notebook. \n",
    "Please see instructions at the bottom of the notebook about how to prepare your solution for handin.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Two Files and Their Fields\n",
    "\n",
    "You have two files, one containing review data, the other containing product data.\n",
    "The format of these files is unusual:  each file has one line per \"data row,\" and a data row is either a single review or a single product, depending on the file.\n",
    "\n",
    "Each line can be converted to a Python dictionary using this \n",
    "code:\n",
    "\n",
    "``eval('(' + line + ')')``\n",
    "\n",
    "By iterating over all of the lines in the review data file and evaluating each line, you can build a list of dictionaries, one per review.  In other words, this is roughly the same as scraping the review pages. And likewise for the product pages data file.  You will use the data in these two lists of dictionaries to index your two SOLR collections.\n",
    "\n",
    "One difference is that when you scrape a page you can select only the attributes that are interesting to your application.  When you read these files in, they will have some extra fields, which you will have to remove from your dictionary (because those fields will not be in your SOLR schema, and SOLR will complain if you send it fields that are not part of its schema).\n",
    "\n",
    "Not all of the fields are interesting to us in the sense we will use them on our web site;  here is information about what the fields mean, and which you should keep and which you should discard (ignore)\n",
    "\n",
    "##### Reviews Data\n",
    "\n",
    "Your solution will only use the following fields;  ignore any others in the data\n",
    "\n",
    "| Field | Type | Note |\n",
    "|-------|------|------|\n",
    "| id | UUID | Not in the input file;  supplied by SOLR the same as you did for Assignment 1\n",
    "| asin | string | Product ID.  Joins with the asin field in the product file |\n",
    "| reviewText | text | Full review body |\n",
    "| overall | integer | Average rating.  Truncate the floating-point value |\n",
    "| summary | text | Review summary text |\n",
    "\n",
    "Unlike the last assignment, we are omitting the review time from our reviews documents.\n",
    "\n",
    "##### Products\n",
    " \n",
    "Your solution will only use the following fields;  ignore any others in the data\n",
    "\n",
    "| Field | Type | Note |\n",
    "|-------|------|------|\n",
    "| asin | string | Unique ID for products.  Joins with the asin field in the reviews file. |\n",
    "| description | string | Stored but not indexed.  Shown on product detail page but not searchable. |\n",
    "| title | string | This is the product name.  Stored but not indexed.  Shown on the product detail page and also on review search result and detail pages. |\n",
    "| price | float | Displayed in currency format on the product detail page.|\n",
    "\n",
    "Notice that for product data, only the ASIN field in products is being indexed.  That means you can't do any kind of search on Products except an ASIN lookup.  Of course in a real e-commerce application you would want to search on product attributes too, but for this assignment we are keeping it simple and only searching on reviews.  \n",
    "\n",
    "Be aware of the implications of this decision -- if for example you do a review search on 'iphone' you will only find reviews that explicitly contain the term 'iphone' in the review summary or the review text, even though the product itself might have 'iphone' in the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Code and How it Will be Used\n",
    "\n",
    "The main deliverables for this assignment are\n",
    "* A directory containing the configuration for your *reviews* collection\n",
    "* A directory containing the configuration for your *products* collection\n",
    "* A directory containing your Flask project\n",
    "\n",
    "Please be careful to name things exactly like this:\n",
    "* The directory containing the configuration for your reviews collection will have the name *reviews*\n",
    "* The name of the SOLR collection will also be named *reviews*\n",
    "* The directory containing the configuration for your products collection will have the name *products*\n",
    "* The name of the SOLR collection will also be named *products*\n",
    "* The name of the directory containing your Flask project will be named *reviewsite*\n",
    "\n",
    "This notebook will contain some code to \"scrape\" the data files and prepare dictionaries for indexing.  Please note that in this notebook you will just write the function definitions  to prepare the dictionaries, similar to the function *scrapePagesForReviews* you wrote for Assignment 1.   \n",
    "\n",
    "Also note that in your code and in your SOLR schemas you must use the exact names in the documentation above.  For example, your *reviews* schema must have fields named *id*, *asin*, *reviewText*, *overall*, and *summary*.  Be careful about capitalization.  The  *products* schema must have fields named *asin*, *description*, *title*, and *price*.  \n",
    "\n",
    "When you \"scrape\" products and reviews you must also follow the following rules, which filter out records with bad data.  In the rules below, \"empty\" means either the value of the attribute is an empty string, or the attribute is missing altogether.\n",
    "\n",
    "For products\n",
    "* Do not include a product if its asin or title fields are empty.  An empty description is OK.\n",
    "* It is OK to have an empty price, but you need to check that the string value you read is a valid positive floating point number.  If the value is not a valid positive floating point number, omit the attribute\n",
    "\n",
    "For reviews\n",
    "* Do not include a review if its asin, summary, or reviewText attributes are empty\n",
    "* It is OK to have an empty *overall* attribute, but you need to check that the string value you read can be converted to an integer between 1 and 5.  If the value cannot be converted to an integer between 1 and 5, omit the attribute\n",
    "* Do not include a review if there is not a product with the same asin\n",
    "   * This last restriction is tricky -- give some thought to its implementation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "def productJSON(filename):\n",
    "    product_set = set()\n",
    "    docs = []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            product_details_dict = eval(line)\n",
    "            filtered_dict = dict()\n",
    "            keys_to_keep = [\"asin\", \"title\"]\n",
    "            skip_iteration = False\n",
    "            for key in keys_to_keep:\n",
    "                if key not in product_details_dict:\n",
    "                    skip_iteration = True\n",
    "                    break\n",
    "                filtered_dict[key] = product_details_dict[key]\n",
    "            \n",
    "            if \"price\" in product_details_dict and (type(product_details_dict[\"price\"]) is not float or product_details_dict[\"price\"] < 0.0):\n",
    "                skip_iteration = True\n",
    "            elif \"price\" in product_details_dict: \n",
    "                filtered_dict[\"price\"] = product_details_dict[\"price\"]\n",
    "            \n",
    "            if \"description\" in product_details_dict:\n",
    "                filtered_dict[\"description\"] = product_details_dict[\"description\"]\n",
    "    \n",
    "            if skip_iteration:\n",
    "                continue\n",
    "            \n",
    "            product_set.add(filtered_dict[\"asin\"])\n",
    "            docs.append(filtered_dict)\n",
    "\n",
    "    pickle.dump(product_set, open(\"products_asin.txt\", \"wb\"))\n",
    "    return docs      \n",
    "    \n",
    "def reviewJSON(filename):\n",
    "    docs = []\n",
    "    products_asin = pickle.load( open( \"products_asin.txt\", \"rb\" ))\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            product_details_dict = eval(line)\n",
    "            filtered_dict = dict()\n",
    "            keys_to_keep = [\"asin\", \"summary\",\"reviewText\"]\n",
    "            skip_iteration = False\n",
    "            for key in keys_to_keep:\n",
    "                if key not in product_details_dict:\n",
    "                    skip_iteration = True\n",
    "                    break\n",
    "                filtered_dict[key] = product_details_dict[key]\n",
    "            \n",
    "            if \"overall\" in product_details_dict and type(product_details_dict[\"overall\"]) is not float:\n",
    "                skip_iteration = True\n",
    "            elif \"overall\" in product_details_dict:\n",
    "                filtered_dict[\"overall\"] = product_details_dict[\"overall\"]\n",
    "            \n",
    "            if filtered_dict[\"asin\"] not in products_asin:\n",
    "                skip_iteration = True\n",
    "                \n",
    "            if skip_iteration:\n",
    "                continue\n",
    "            \n",
    "            docs.append(filtered_dict)\n",
    "    return docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"\\nCreated new core 'reviews'\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For \"shell commands\" in Windows.  Replace it if you're not Windows\n",
    "import subprocess\n",
    "\n",
    "SOLR_EXECUTABLE = '/Users/sonalidesarda/Documents/Softwares/solr-8.11.1/bin/solr'\n",
    "\n",
    "def solr_command(*args):\n",
    "    return subprocess.check_output([SOLR_EXECUTABLE] + list(args))\n",
    "config_loc = '/Users/sonalidesarda/Downloads/cpsc5340-w22-main-Assignment1/Assignment2/products/conf'\n",
    "solr_command('create_core', '-c', 'products', '-d', config_loc)\n",
    "config_loc = '/Users/sonalidesarda/Downloads/cpsc5340-w22-main-Assignment1/Assignment2/reviews/conf'\n",
    "solr_command('create_core', '-c', 'reviews', '-d', config_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"responseHeader\":{\\n    \"status\":0,\\n    \"QTime\":333}}\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pysolr\n",
    "import json\n",
    "\n",
    "prod = productJSON(\"test-products.txt\")\n",
    "solr = pysolr.Solr('http://localhost:8983/solr/products')\n",
    "solr.add(prod, commit=True)\n",
    "rev = reviewJSON(\"test-reviews.txt\")\n",
    "solr = pysolr.Solr('http://localhost:8983/solr/reviews')\n",
    "solr.add(rev, commit=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How I Will Run Your Solution\n",
    "\n",
    "I will start in a directory that contains\n",
    "* This notebook (the notebook you hand in)\n",
    "* Your two configuration directories you hand in, which must be named *products* and *reviews*\n",
    "* The directory you hand in containing your Flask application, which must be named *reviewsite*\n",
    "* My test data files, which might be named *testProductData.txt* and *testReviewData.txt*\n",
    "\n",
    "SOLR will be running and have no collections defined.\n",
    "\n",
    "I will do the following\n",
    "* Create the *products* and *reviews* collections using the directories you provided.  For example\n",
    "<pre>\n",
    "solr create_collection -c products -d products\n",
    "solr create_collection -c reviews -d reviews\n",
    "</pre>\n",
    "* Index \"documents\" using the \"scraping\" code you defined above, pointing your code to my test files.  For example.\n",
    "<pre>\n",
    "prod = productJSON(\"my-test-product-data.txt\")\n",
    "solr = pysolr.Solr('http://localhost:8983/solr/products')\n",
    "solr.add(prod, commit=True)\n",
    "</pre>\n",
    "<pre>\n",
    "rev = reviewJSON(\"my-test-review-data.txt\")\n",
    "solr = pysolr.Solr('http://localhost:8983/solr/reviews')\n",
    "solr.add(rev, commit=True)\n",
    "</pre>\n",
    "* Start Flask, pointing it at your project directory.  For example.\n",
    "<pre>\n",
    "set FLASK_APP=reviewsite\n",
    "set FLASK_DEBUG=1\n",
    "flask run\n",
    "</pre>\n",
    "* Then I will do searches and lookups and overall test the functionality of your site on the test data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Prepare This Notebook to Hand In\n",
    "Your notebook should contain only two cells, in this order\n",
    "1.  A Markdown cell containing your name, the course number and name, the quarter, and identifies it as a solution for Assignment 2\n",
    "2.  A Code cell that contains your function definitions for *productJSON* and *reviewJSON*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
